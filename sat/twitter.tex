\documentclass{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{subfig}

\graphicspath{{Results/Fig/}}

\title{How's the tone of Mexican social media?}
\author{Jos\'e Manuel Rodr\'iguez Sotelo}

\begin{document}
\maketitle

\section{Introduction}
Lately, there has been an explosion of interest in the analysis of data generated by the social interactions of people in the web. The value of data analysis has been recognized because of its applications. For instance, it is possible to predict how influential a person is in a social network.\footnote{\url{https://www.kaggle.com/c/predict-who-is-more-influential-in-a-social-network}} Also, romantic partnerships can be inferred solely from the structure of social networks in facebook.\footnote{\url{http://arxiv.org/pdf/1310.6753v1.pdf}} Because of the increased availability of large-scale data, tools are needed to extract valuable information. Fortunately, the tools and the data are available for everyone.

\section{Data Collection}
The first step towards performing the analysis is to collect social media information. Since Twitter offeres most of its data online for free, I decided to use information of mexican tweets using the Twitter Python API. The data used in this paper consist of $1.5$ million tweets published between July 17th and July 27th. The figure \ref{fig:tweets_location} shows the location of all the tweets considered in the analysis.

\begin{figure}[ht]
	\includegraphics{tweets_location}
	\caption{Tweets' location map.}
	\label{fig:tweets_location}
\end{figure}

\section{Sentiment Analysis}
The methodology is quite standard. First, I assign a score to a set of words. Second, I evaluate every tweet according to the scores of its words. Furthermore, the score of the tweet consists of the sum of the scores of its labeled words.

I use the dictionary labeled by Finn {\AA}rup Nielsen. This dataset contains $2477$ manually scored words in English. I use machine translation to get the scores of spanish words. The translation was done automatically using the goslate API.\footnote{\url{http://pythonhosted.org/goslate/}}

\subsection{Dictionary Learning}
After the translation, I have sentiment scores for $2024$ words in spanish. Unfortunately, these words don't appear in the majority of tweets. Therefore, before attempting to evaluate the score of every tweet, I extend the sentiment' information to other words. I use a sample of 10,000 tweets and a simple algorithm to perform the inference. The underlying assumption of this algorithm is that positive words appear more frequently with other positive words.

\section{Results}
The table \ref{table:top} and the figure \ref{fig:states_sentiment} summarize the results of the analysis.
\begin{figure}[ht]
	\includegraphics{map}
	\caption{States' Sentiment}
	\label{fig:states_sentiment}
\end{figure}

\begin{table}[ht]
	\centering
	\subfloat[Positive States]
	{
		\begin{tabular}{lr}
			\input{Results/Table/best.tex}
		\end{tabular}
	}
	\quad
	\subfloat[Negative States]
	{
		\begin{tabular}{lr}
			\input{Results/Table/worst.tex}
		\end{tabular}
	}
	\caption{Top states according to their sentiment scores}
	\label{table:top}
\end{table}

\section{Final Remarks}
There are several details regarding this analysis that I would like to address. First, a robustness check of the analysis is neccesary. There are several alternatives that could be explored. For instance, repeating the analysis with a different twitter data set and look for consistence in the results. Furthermore, a different dictionary could be used.\footnote{\url{http://crr.ugent.be/archives/1003}}

Alternatively, an entirely different approach could be used. Probably the most effective approach to construct an informative analysis of the tone of conversations would involve using deep learning models to build up a representation of whole sentences based on the sentence structure. For instance, Socher \emph{et. al } have built a deep learning model for the sentiment of movie reviews.\footnote{\url{http://nlp.stanford.edu/sentiment/}} Even though some resources are needed to complete this task, in particular, a large enough sample of labeled data, the results of this model would outperform the simple approach followed in this paper.

\end{document}